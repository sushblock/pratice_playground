{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591e4641",
   "metadata": {},
   "source": [
    "\n",
    "# Build a real-world agent\n",
    "Next, build a practical weather forecasting agent that demonstrates key production concepts:\n",
    "Detailed system prompts for better agent behavior\n",
    "Create tools that integrate with external data\n",
    "Model configuration for consistent responses\n",
    "Structured output for predictable results\n",
    "Conversational memory for chat-like interactions\n",
    "Create and run the agent create a fully functional agent\n",
    "Let’s walk through each step:\n",
    "\n",
    "1\n",
    "Define the system prompt\n",
    "\n",
    "The system prompt defines your agent’s role and behavior. Keep it specific and actionable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349c3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280dc4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe4f46",
   "metadata": {},
   "source": [
    "2\n",
    "Create tools\n",
    "\n",
    "Tools let a model interact with external systems by calling functions you define. Tools can depend on runtime context and also interact with agent memory.\n",
    "Notice below how the get_user_location tool uses runtime context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161bc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25012f21",
   "metadata": {},
   "source": [
    "3\n",
    "Configure your model\n",
    "\n",
    "Set up your language model with the right parameters for your use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6771f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\", temperature=0.5, max_retries=3, timeout=60, max_tokens=1000, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb371e",
   "metadata": {},
   "source": [
    "4\n",
    "Define response format\n",
    "\n",
    "Optionally, define a structured response format if you need the agent responses to match a specific schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e4cdb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b51cb",
   "metadata": {},
   "source": [
    "5\n",
    "Add memory\n",
    "\n",
    "Add memory to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126f8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851ca3b",
   "metadata": {},
   "source": [
    "6\n",
    "Create and run the agent\n",
    "\n",
    "Now assemble your agent with all the components and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2eede3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"Looks like Florida is serving up its signature dish—sunshine with a side of vitamin sea! It's always sunny in Florida, so sunglasses are practically a dress code. Stay cool, sun-chaser!\", weather_conditions=\"It's always sunny in Florida!\")\n",
      "ResponseFormat(punny_response=\"You're welcome! If you ever need another weather update, just give me a shout—I'm always ready to sprinkle a little sunshine on your day. Have a weather-ful time!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
